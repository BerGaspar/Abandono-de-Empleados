# -*- coding: utf-8 -*-
"""Empleados.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uXV10IHDIfRGv_Ju8edL2ASeLVZucFt4

> # RETENCION DE EMPLEADOS
> ![descarga.png](data:image/png;base64,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)

## ABSTRACT

La base de datos proporciona un conjunto de **2064 registros** de empleados y ex empleados de una empresa española, actualizados hasta 2023. Este dataset incluye **31 variables** que describen diversos aspectos como la edad, el abandono, los viajes, el departamento, la distancia desde el hogar, la educación, la carrera, el número de empleados, la satisfacción con el entorno laboral, el sexo, la implicación, el nivel laboral, el puesto, la satisfacción laboral, el estado civil, el salario mensual, el número de empresas anteriores, la edad máxima, las horas extra, el incremento salarial porcentual, la evaluación, la satisfacción con los compañeros, las horas trabajadas por quincena, el nivel de acciones, los años de experiencia, el número de formaciones recibidas el último año, la conciliación, los años en la compañía, los años en el puesto actual, los años desde la última promoción y los años con el manager actual.


Decidí utilizar este dataset debido a la **credibilidad y realismo de los datos**, en contraposición a la abundancia de datasets con datos sintéticos.


El objetivo principal de este conjunto de datos es analizar por qué la **tasa de abandono de empleados** es tan alta y encontrar patrones comunes que puedan explicar este fenómeno. Asimismo, se busca predecir la probabilidad de abandono de futuros empleados si no se realizan cambios. Este proyecto pretende ayudar a la empresa a identificar áreas de mejora que podrían haber pasado desapercibidas, con el fin de optimizar el rendimiento de sus empleados sin recurrir necesariamente al despido o a la búsqueda de nuevos talentos.


*El objetivo concreto es desarrollar un modelo capaz de detectar patrones subyacentes que puedan explicar el abandono de empleados y ex empleados, así como otro modelo que pueda predecir la tasa de abandono de próximos empleados.*

### CARGA DE LIBRERIAS
"""

# Commented out IPython magic to ensure Python compatibility.
#Librerias para

import numpy as np
import pandas as pd

#Librerias para Graficos

import matplotlib as mpl
import matplotlib.pyplot as plt
# %matplotlib inline
plt.style.use('fivethirtyeight')
import seaborn as sns

#Librerias para APIs

import requests
import json

#Librerias para modelo

"""### CARGA DE LOS DATOS"""

from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv('AbandonoEmpleados.csv', sep = ';', index_col= 'id', na_values='#N/D')
df

# Ejecutar cada vez que se reeconecte y cargue de 0 el df
df.drop( columns = ['anos_en_puesto','conciliacion'], inplace = True)
df.drop(columns = 'mayor_edad', inplace = True)
df.drop(columns = ['empleados','sexo','horas_quincena'], inplace = True)
df['educacion'] = df['educacion'].fillna('Universitaria')
df['satisfaccion_trabajo'] = df['satisfaccion_trabajo'].fillna('Alta')
df['implicacion'] = df['implicacion'].fillna('Alta')

"""---
<br/><br/>

## DATA WRANGLING (CALIDAD Y LIMPIEZA DE DATOS)

### Nombre de Variables
"""

df.columns

"""### Descripcion de Variables

Edad

    edad de empleado
    Variable numérica continua (int).

Abandono

    si actualmente se encuentra fuera de la empresa
    Variable numérica continua (int).

Viajes

    si el empleado viaja y si lo hace con cuanta frecuencia
    Variable numérica continua (int).

Departamento

    en que sector/departamento de la empresa se encuentra
    Variable numérica continua (int).

Distancia casa

    distancia entre trabajo y vivienda en km
    Variable numérica continua (int).

Educacion

    que nivel educativo cuanta
    Variable numérica continua (int).

Carrera

    que carrera ejerce o estudia
    Variable numérica continua (int).

Empleados

    ???
    Variable numérica continua (int).

Satisfaccion entorno

    nivel de satisfaccion en su entorno de trabajo
    Variable numérica continua (int).

Sexo

    sexo/genero
    Variable numérica continua (int).

Implicacion

    el grado en que una persona se identifica psicológicamente con su trabajo
    Variable numérica continua (int).

Nivel laboral

    nivel laboral 1-10
    Variable numérica continua (int).

Puesto

    labor o puesto que desarrolla dentro del departamento
    Variable numérica continua (int).

Satisfaccion trabajo

    nivel de satisfaccion con su trabajo
    Variable numérica continua (int).

Estado civil

    estado civil
    Variable numérica continua (int).

Salario mes

    cantidad remunerada por su trabajo
    Variable numérica continua (int).

Num empresas anteriores

    cantidad de trabajos anteriores al actual
    Variable numérica continua (int).

Mayor edad

    si el individuo es mayor de edad (+18)
    Variable numérica continua (int).

Horas_extra

    el individuo realiza horas extras de trabajo
    Variable numérica continua (int).

Incremento salario porc

    porcentaje de aumento salarial
    Variable numérica continua (int).

Evaluacion

    ???
    Variable numérica continua (int).

Satisfaccion companeros

    nivel de satisfaccion con sus compañeros de trabajo
    Variable numérica continua (int).

Horas quincena

    cantidad de horas de trabajo realizadas por quincena
    Variable numérica continua (int).

Nivel acciones

    ???
    Variable numérica continua (int).

Años experiencia

    cantidad de años de experiencia en la profecion
    Variable numérica continua (int).

Num formaciones ult ano

    cantidad de formaciones realizadas a empleados en el ultimo año
    Variable numérica continua (int).

Conciliacion

    cantidad de conflictos laborales entre un empleado y su empleador solucionadas
    Variable numérica continua (int).

AÑos_compania

    cantidad de años en la compañia
    Variable numérica continua (int).

AÑos en puesto

    cantidad de años en el puesto actual
    Variable numérica continua (int).

AÑos desde ult promocion

    cantidad de años desde la ultima promocion
    Variable numérica continua (int).

AÑos con manager actual

    cantidad de años con el manager actual
    Variable numérica continua (int).

### Vision General
"""

df.head()

df.describe()

"""### Tipo de Datos"""

df.info()

"""### Limpieza de Datos

#### Valores Nulos
"""

df.isna().sum().sort_values(ascending = False)

"""Conclusiones:

*   anos_en_puesto y conciliacion tienen demasiados nulos --> eliminar Variables  (*Solo en caso de que la coorelacion con la variable objetivo sea baja*)
*   sexo, educacion, satisfaccion_trabajo e implicacion --> imputarlos tras EDA
"""

df.drop( columns = ['anos_en_puesto','conciliacion'], inplace = True)
df.columns

"""#### Valores Duplicados"""

duplicados = df[df.duplicated()]
if len(duplicados) > 0:
  print('Datos Duplicados:\n', duplicados)
  df= df.drop_duplicates()
  print('Se borraron los datos duplicados')
else:
  print('No hay duplicados en el DataFrame')

"""#### Valores Atipicos

##### Variables Categorica
"""

columnas_categoricas = df.select_dtypes(include=['object'])

# umbral para la rareza de las categorías
umbral_rareza = 0.05  # frecuencia menor al 5% es atípica

for columna in columnas_categoricas.columns:

    frecuencia_valores = df[columna].value_counts(normalize=True)
    valores_atipicos = frecuencia_valores[frecuencia_valores < umbral_rareza]

    if not valores_atipicos.empty:

        print(f"Valores atípicos en la columna '{columna}':")
        print(valores_atipicos)
        print()

"""Si las variables estas tienen una alta coorelacion con el nivel de abandono se tendra en cuanta sacar estos valores a la hora de armar el modelo

##### Variables Numéricas

###### **Desviacion Estandar**
"""

columnas_numericas = df.select_dtypes(include=['float64', 'int64'])
desviacion_tipica = columnas_numericas.std()
umbral_desviacion = 3

for columna in columnas_numericas.columns:

    media_columna = df[columna].mean()

    limite_inferior = media_columna - umbral_desviacion * desviacion_tipica[columna]
    limite_superior = media_columna + umbral_desviacion * desviacion_tipica[columna]

    # Filtrar valores que están fuera de los límites
    valores_atipicos = df[(df[columna] < limite_inferior) | (df[columna] > limite_superior)]

    if not valores_atipicos.empty:
        print(f"Valores atípicos en la columna '{columna}':")
        print(valores_atipicos)
        print()

"""###### **Winsorización**

*Técnica que se utiliza para tratar los valores atípicos en variables numéricas. Consiste en reemplazar los valores extremos por valores menos extremos, generalmente los valores que se encuentran en los percentiles especificados.*

 Siempre es recomendable realizar un análisis exploratorio de los datos antes de decidir si la winsorización es adecuada para tu situación específica.

 Se realizara esta de acuerdo al resultado de la coorelacion de variables con el nivel de abandono y se aplicara si es necesario.

 **NO EJECUTAR HASTA ESTAR REALIZADO EL EDA CORRECTAMENTE!**
"""

from scipy.stats.mstats import winsorize

# Winsorización automática
columna_winsorizada = winsorize(columna, limits=[0.05, 0.05]) # Reemplazar por columnas a las que se aplicaran

"""###### **Metodo de Colas**

Metodo para reemplazar los valores atípicos con los valores que están en los percentiles extremos de la distribución de datos.

Es importante tener en cuenta que este método también tiene sus limitaciones y debe usarse con cuidado, seleccionando los percentiles extremos de manera apropiada y considerando las implicaciones en la interpretación de los resultados.

Luego de realizar un correcto EDA se valorara su uso.

 **NO EJECUTAR HASTA ESTAR REALIZADO EL EDA CORRECTAMENTE!**
"""

columnas_numericas = df.select_dtypes(include=[np.number])

# Percentiles extremos para las colas (por ejemplo, percentil 1 y 99)
p1 = df.quantile(0.01)
p99 = df.quantile(0.99)

# Método de las colas
for columna in columnas_numericas.columns:
    df[columna] = np.where(df[columna] < p1[columna], p1[columna], np.where(df[columna] > p99[columna], p99[columna], df[columna])) # Modificar por las columnas que se desee aplicar

"""---
<br/><br/>

## EDA (Analisis Exploratorio de Datos)

### ANALISIS ESTADISTICO

#### **Analisis de Frecuencias**

*Observar con qué frecuencia ocurren los diferentes valores de esa variable en un conjunto de datos.*

#### VARIABLES CATEGORICAS
"""

def graficos_eda_categoricos(cat):

    #Calculamos el número de filas que necesitamos
    from math import ceil
    filas = ceil(cat.shape[1] / 2)

    #Definimos el gráfico
    f, ax = plt.subplots(nrows = filas, ncols = 2, figsize = (16, filas * 6))

    #Aplanamos para iterar por el gráfico como si fuera de 1 dimensión en lugar de 2
    ax = ax.flat

    #Creamos el bucle que va añadiendo gráficos
    for cada, variable in enumerate(cat):
        cat[variable].value_counts().plot.barh(ax = ax[cada])
        ax[cada].set_title(variable, fontsize = 12, fontweight = "bold")
        ax[cada].tick_params(labelsize = 12)

graficos_eda_categoricos(df.select_dtypes('O'))

"""**Conclusiones:**

*   mayor_edad solo tiene un valor --> eliminarla (una variable con un solo valor no aporta informacion)
*   Sobre las imputaciones pendientes de variables categóricas:
  * educacion (101 valores nulos): imputar por 'Universitaria' (moda)
  * satisfaccion_trabajo (76 valores nulos): imputar por 'Alta'
  * implicacion (18 valores nulos): imputar por 'Alta'
"""

df.drop(columns = 'mayor_edad', inplace = True)

df['educacion'] = df['educacion'].fillna('Universitaria')

df['satisfaccion_trabajo'] = df['satisfaccion_trabajo'].fillna('Alta')

df['implicacion'] = df['implicacion'].fillna('Alta')

"""#### VARIABLES NUMÉRICAS"""

fig, axes = plt.subplots(nrows=6, ncols=3, figsize=(17, 13))
axes = axes.flat

columnas_numeric = df.select_dtypes(include=['float64', 'int']).columns

# Obtén la lista de colores del ciclo de propiedades de Matplotlib
colores = [color['color'] for color in plt.rcParams['axes.prop_cycle']]

for i, colum in enumerate(columnas_numeric):
    sns.histplot(
        data    = df,
        x       = colum,
        stat    = "count",
        kde     = True,
        color   = colores[i % len(colores)],  # Usa el operador módulo (%) para asegurarte de que el índice esté dentro del rango válido de la lista de colores
        line_kws= {'linewidth': 2},
        alpha   = 0.3,
        ax      = axes[i]
    )
    axes[i].set_title(colum, fontsize = 9, fontweight = "bold")
    axes[i].tick_params(labelsize = 6)
    axes[i].set_xlabel("")
    axes[i].set_ylabel("")

# Ajusta el diseño y el espacio entre subgráficos
fig.tight_layout()
plt.subplots_adjust(top = 0.9)
fig.suptitle('Distribución variables numéricas', fontsize = 10, fontweight = "bold")

# Eliminar los ejes que no se están utilizando
num_columnas = len(columnas_numeric)
for i in range(num_columnas, len(axes)):
    fig.delaxes(axes[i])

def estadisticos_cont(num):
    #Calculamos describe
    estadisticos = num.describe().T
    #Añadimos la mediana
    estadisticos['median'] = num.median()
    #Reordenamos para que la mediana esté al lado de la media
    estadisticos = estadisticos.iloc[:,[0,1,8,2,3,4,5,6,7]]

    return(estadisticos)

estadisticos_cont(df.select_dtypes('number'))

"""Conclusiones:

* Empleados solo tiene un valor --> Eliminarla
* Sexo tiene 4 valores y estos no especifican a que hacen referencia--> Eliminarla o pedir retroalimentacion a la hora de entregar proyecto
* Horas quincena solo tiene una valor --> Eliminarla
* De los nulos pendientes de imputación que sean numéricas solo está el sexo, pero como la vamos a eliminar ya no hay que imputar nada
"""

df.drop(columns = ['empleados','sexo','horas_quincena'], inplace = True)
df.columns

"""### **MULITIVARIATE ANALYTICS**

Como nuestro objetivo es analizar el nivel de desempleo se necesitara comparar esta variable con las otras y ver cual es su coorelacion.

#### Coorelacion de variables coonciliacion y años en puesto
"""

def coorelacon(df):
      df_map = df.copy()

      df_map['abandono'] = df['abandono'].map({'Yes': 1, 'No': 0})
      df_map['conciliacion'] = df['conciliacion'].map({'Baja': 0, 'Muy_Alta': 3, 'Media': 1, 'Alta': 2})

      correlation_conciliacion = df_map['abandono'].corr(df_map['conciliacion'], method='pearson')  # Cambia 'pearson' por 'spearman' o 'kendall' según sea necesario
      print("Correlación entre 'abandono' y 'conciliacion':", correlation_conciliacion)

      correlation_años_en_puesto = df_map['abandono'].corr(df_map['anos_en_puesto'], method='pearson')  # Cambia 'pearson' por 'spearman' o 'kendall' según sea necesario
      print("Correlación entre 'abandono' y 'anos_en_puesto':", correlation_años_en_puesto)

coorelacon(df)

"""Correlación entre 'abandono' y 'conciliacion': -0.1364

*   Esta correlación es negativa y cercana a cero. Indica una relación débil entre 'abandono' y 'conciliacion'. La correlación negativa sugiere que a medida que el valor de 'conciliacion' aumenta, es más probable que el valor de 'abandono' disminuya, y viceversa. Sin embargo, la correlación cercana a cero indica que la relación es débil.

Correlación entre 'abandono' y 'anos_en_puesto': -0.2189

*   Esta correlación también es negativa y más cercana a -0.22. Al igual que antes, indica una relación débil entre 'abandono' y 'anos_en_puesto'. La correlación negativa sugiere que a medida que el número de 'anos_en_puesto' aumenta, es menos probable que un empleado abandone, y viceversa, pero nuevamente, la correlación cercana a cero sugiere que esta relación es débil.
"""

def plot_heatmap(df):

    df_map = df.copy()

    df_map['abandono'] = df['abandono'].map({'Yes': 1, 'No': 0})
    df_map['conciliacion'] = df['conciliacion'].map({'Baja': 0, 'Muy_Alta': 3, 'Media': 1, 'Alta': 2})

    plt.figure(figsize=(10, 8))
    heatmap = sns.heatmap(df_map.corr(), annot=True, annot_kws={"size": 8})
    sns.set(font_scale=0.8)
    plt.title("Heatmap de Correlación")

    return heatmap

heatmap = plot_heatmap(df)
plt.show()

# Calculo de Coheficiente de Correlacion de las columnas
def coor_num():
    columnas_numeric = df.select_dtypes(include=['float64', 'int']).columns
    df_map = df.copy()

    df_map['abandono'] = df['abandono'].map({'Yes': 1, 'No': 0})

    for columna in columnas_numeric:
        coef_corr = df_map['abandono'].corr(df[columna])
        fuerza = ''

        if abs(coef_corr) < 0.20:
            fuerza = 'Muy débil'
        elif 0.20 <= abs(coef_corr) < 0.40:
            fuerza = 'Débil'
        elif 0.40 <= abs(coef_corr) < 0.60:
            fuerza = 'Moderada'
        elif 0.60 <= abs(coef_corr) < 0.80:
            fuerza = 'Fuerte'
        elif 0.80 <= abs(coef_corr) <= 1.0:
            fuerza = 'Muy fuerte'


        print(f"Coeficiente de correlación entre 'precio' y '{columna}': {coef_corr:.4f} ({fuerza})")

coor_num()

"""**Conclusiones:**

* anos_en_puesto y conciliacion tienen demasiados nulos y su coorelacion con la variable objetivo es muy baja --> eliminar Variables

#### Correlación entre variables categóricas y la variable objetivo 'abandono'

---
<br/><br/>

## INFERENCIA ESTADISTICA Y GENERACION DE INSIGTHS

### Establecer Hipotesis, Preguntas y Verificar condiciones

*   **Cuantificación del problema: ¿Cual es la tasa de abandono?**
"""

df.abandono.value_counts(normalize = True) * 100

"""La empresa cuenta con una tasa de abandono de un 16.1%

*   **¿Hay un perfil tipo de empleado que deja la empresa?**
"""

df['abandono'] = df['abandono'].map({'No': 0, 'Yes': 1})

columns_of_interest = ['educacion', 'estado_civil', 'horas_extra', 'puesto']

fig, axs = plt.subplots(2, 2, figsize=(12, 10))

for i, column in enumerate(columns_of_interest):
    row = i // 2
    col = i % 2
    temp = df.groupby(column).abandono.mean().sort_values(ascending=False) * 100
    temp.plot.bar(ax=axs[row, col])
    axs[row, col].set_title(column.capitalize())

plt.tight_layout()
plt.show()

temp = df.groupby('abandono').salario_mes.mean()
temp.plot.bar();

temp = df.groupby('abandono').distancia_casa.mean()
temp.plot.bar();

"""**Conclusiones:**

El perfil medio del empleado que deja la empresa es:

* Bajo nivel educativo
* Soltero
* Trabaja en ventas
* Bajo salario
* Alta carga de horas extras
* Mayor distancia del hogar a la empresa

### BUISSNES ANALYTICS

*   **¿Cual es el impacto económico de este problema?**

Según el estudio "Cost of Turnover" del Center for American Progress:

* El coste de la fuga de los empleados que ganan menos de 30000 es del 16,1% de su salario

* El coste de la fuga de los empleados que ganan entre 30000-50000 es del 19,7% de su salario

* El coste de la fuga de los empleados que ganan entre 50000-75000 es del 20,4% de su salario

* El coste de la fuga de los empleados que ganan más de 75000 es del 21% de su salario
"""

# Creamos una nueva variable salario_ano del empleado
df['salario_ano'] = df.salario_mes.transform(lambda x: x*12)
df[['salario_mes','salario_ano']]

# Calculamos el impacto económico de cada empleado si deja la empresa

#Lista de condiciones
condiciones = [(df['salario_ano'] <= 30000),
               (df['salario_ano'] > 30000) & (df['salario_ano'] <= 50000),
               (df['salario_ano'] > 50000) & (df['salario_ano'] <= 75000),
               (df['salario_ano'] > 75000)]

#Lista de resultados
resultados = [df.salario_ano * 0.161, df.salario_ano * 0.197, df.salario_ano * 0.204, df.salario_ano * 0.21]

#Aplicamos select
df['impacto_abandono'] = np.select(condiciones,resultados, default = -999)

df

"""*   **¿Cúanto nos ha costado este problema en el último año?**"""

coste_total =  df.loc[df.abandono == 1].impacto_abandono.sum()
print('El problema ha costado un total de ', coste_total, '€ este año')

"""*   **¿Cuanto nos cuesta que los empleados no estén motivados? (pérdidas en implicación == Baja)**"""

motivacion = df.loc[(df.abandono == 1) & (df.implicacion == 'Baja')].impacto_abandono.sum()
print('Lo que nos cuersta que lo empleados no esten motivados es de ', motivacion, '€')

"""*   **¿Cuanto dinero podríamos ahorrar fidelizando mejor a nuestros empleados?**"""

print(f"Reducir un 10% la fuga de empleados nos ahorraría {int(coste_total * 0.1)} € cada año.")

print(f"Reducir un 20% la fuga de empleados nos ahorraría {int(coste_total * 0.2)} € cada año.")

print(f"Reducir un 30% la fuga de empleados nos ahorraría {int(coste_total * 0.3)} € cada año.")

"""### Y podemos seguir trazando estrategias asociadas a los insights de abandono:

Habíamos visto que los representantes de ventas son el puesto que más se van. ¿Tendría sentido hacer un plan específico para ellos? ¿Cual sería el coste ahorrado si disminuimos la fuga un 30%?

Primero vamos a calcular el % de representantes de ventas que se han ido el año pasado
"""

total_repre_pasado = len(df.loc[df.puesto == 'Sales Representative'])
abandonos_repre_pasado = len(df.loc[(df.puesto == 'Sales Representative') & (df.abandono == 1)])
porc_pasado = abandonos_repre_pasado / total_repre_pasado

porc_pasado

"""Ahora vamos a estimar cuántos se nos irán este año"""

total_repre_actual = len(df.loc[(df.puesto == 'Sales Representative') & (df.abandono == 0)])
se_iran = int(total_repre_actual * porc_pasado)

se_iran

"""Sobre ellos cuantos podemos retener (hipótesis 30%) y cuanto dinero puede suponer"""

retenemos = int(se_iran * 0.3)

ahorramos = df.loc[(df.puesto == 'Sales Representative') & (df.abandono == 0),'impacto_abandono'].sum() * porc_pasado * 0.3

print(f'Podemos retener {retenemos} representantes de ventas y ello supondría ahorrar {ahorramos}$.')

"""Este dato también es muy interesante porque nos permite determinar el presupuesto para acciones de retención por departamento o perfil.

Ya que sabemos que podemos gastarnos hasta 37.000$ sólo en acciones específicas para retener a representantes de ventas y se estarían pagando sólas con la pérdida evitada

---
<br/><br/>

## MODELO DE MACHINE LEARNING
"""

df_ml = df.copy()

df_ml.info()

"""### PREPARACIÓN DE LOS DATOS PARA LA MODELIZACIÓN

#### Transformar todas las variables categóricas a númericas
"""

from sklearn.preprocessing import OneHotEncoder

#Categóricas
cat = df_ml.select_dtypes('O')

#Instanciamos
ohe = OneHotEncoder(sparse = False)

#Entrenamos
ohe.fit(cat)

#Aplicamos
cat_ohe = ohe.transform(cat)

#Ponemos los nombres
cat_ohe = pd.DataFrame(cat_ohe, columns = ohe.get_feature_names_out(input_features = cat.columns)).reset_index(drop = True)

cat_ohe

"""#### Dataframe final

Seleccionamos las variables numéricas para poder juntarlas a las cat_hoe
"""

num = df.select_dtypes('number').reset_index(drop = True)

"""Las juntamos todas en el dataframe final"""

df_ml = pd.concat([cat_ohe,num], axis = 1)
df_ml

"""### DISEÑO DE LA MODELIZACIÓN

#### Separación predictoras y target
"""

x = df_ml.drop(columns='abandono')
y = df_ml['abandono']

"""#### Separación train y test"""

from sklearn.model_selection import train_test_split

train_x, test_x, train_y, test_y = train_test_split(x, y, test_size = 0.3)

"""### ENTRENAMIENTO DEL MODELO SOBRE TRAIN"""

from sklearn.tree import DecisionTreeClassifier

#Instanciar
ac = DecisionTreeClassifier(max_depth=4)

#Entrenar
ac.fit(train_x,train_y)

"""### PREDICCIÓN Y VALIDACIÓN SOBRE TEST"""

# Predicción
pred = ac.predict_proba(test_x)[:, 1]
pred[:20]

# Evaluación
from sklearn.metrics import roc_auc_score

roc_auc_score(test_y,pred)

"""### INTERPRETACIÓN

#### Diagrama del árbol
"""

from sklearn.tree import plot_tree

plt.figure(figsize = (50,50))

plot_tree(ac,
          feature_names= test_x.columns,
          impurity = False,
          node_ids = True,
          proportion = True,
          rounded = True,
          precision = 2);

"""#### Importancia de las variables"""

pd.Series(ac.feature_importances_,index = test_x.columns).sort_values(ascending = False).plot(kind = 'bar', figsize = (30,20));

"""### EXPLOTACIÓN

Incoporación del scoring al dataframe principal
"""

df['scoring_abandono'] = ac.predict_proba(df_ml.drop(columns = 'abandono'))[:, 1]
df

"""Ejemplo de los 10 empleados con mayor probabilidad de dejar la empresa"""

df.sort_values(by = 'scoring_abandono', ascending = False)[0:10]

"""Ejemplo: riesgo de dejar la empresa por puesto de trabajo"""

df.boxplot(column='scoring_abandono', by='puesto', figsize = (20,12));

"""### GUARDAR EL RESULTADO"""

df

from google.colab import files

df.to_excel('abandono_con_scoring.xlsx')
files.download('abandono_con_scoring.xlsx')